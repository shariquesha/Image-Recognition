{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Quadro K5000 (CNMeM is enabled with initial size: 80.0% of memory, CuDNN 3007)\n",
      "/home/raghib/major_pro/cnn/local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import bob\n",
    "import bob.io.base\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import adam\n",
    "from lasagne.updates import nesterov_momentum\n",
    "\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import TrainSplit\n",
    "\n",
    "from nolearn.lasagne import BatchIterator\n",
    "# from nolearn.lasagne import visualize\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A SAMPLE OF DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    a=X_train.reshape((X_train.shape[0],X_train.shape[2],X_train.shape[3],X_train.shape[1]))\n",
    "#     print X_train.shape\n",
    "    plt.imshow(a[i])\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(a[i])\n",
    "\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "del a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# READING TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "pkl=open('/home/sharique/minor/dataset/training.pkl','rb')\n",
    "total=pickle.load(pkl)\n",
    "for item in total:\n",
    "    X_train.append(item[0])\n",
    "    y_train.append(item[1])\n",
    "\n",
    "pkl.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "net = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('dense', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    input_shape=(None, 3, 150, 150),\n",
    "    conv2d1_num_filters=20,\n",
    "    conv2d1_filter_size=(5, 5),\n",
    "    conv2d1_stride=(1, 1),\n",
    "    conv2d1_pad=(2, 2),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    maxpool1_pool_size=(2, 2),\n",
    "    conv2d2_num_filters=20,\n",
    "    conv2d2_filter_size=(5, 5),\n",
    "    conv2d2_stride=(1, 1),\n",
    "    conv2d2_pad=(2, 2),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    maxpool2_pool_size=(2, 2),\n",
    "    dense_num_units=1000,\n",
    "    dense_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=11,\n",
    "    update=nesterov_momentum,\n",
    "    update_momentum=0.9,\n",
    "    update_learning_rate=0.0001,\n",
    "    max_epochs=100,\n",
    "    batch_iterator_train=BatchIterator(batch_size=100),\n",
    "    train_split=TrainSplit(eval_size=0.0),\n",
    "    verbose=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bashir/.virtualenvs/video_classification/lib/python2.7/site-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 27403551 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ----------\n",
      "  0  input     3x150x150\n",
      "  1  conv2d1   20x150x150\n",
      "  2  maxpool1  20x75x75\n",
      "  3  conv2d2   20x75x75\n",
      "  4  maxpool2  20x37x37\n",
      "  5  dense     1000\n",
      "  6  output    11\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1      \u001b[36m68.57963\u001b[0m       \u001b[32m2.39662\u001b[0m     28.61511      0.13920  25.67s\n",
      "      2       \u001b[36m2.39557\u001b[0m       \u001b[32m2.39551\u001b[0m      1.00002      0.13778  23.18s\n",
      "      3       \u001b[36m2.39436\u001b[0m       \u001b[32m2.39278\u001b[0m      1.00066      0.15199  23.17s\n",
      "      4       \u001b[36m2.39280\u001b[0m       \u001b[32m2.39145\u001b[0m      1.00056      0.15270  23.25s\n",
      "      5       \u001b[36m2.38951\u001b[0m       \u001b[32m2.38784\u001b[0m      1.00070      0.15341  23.22s\n",
      "      6       \u001b[36m2.38653\u001b[0m       \u001b[32m2.38596\u001b[0m      1.00024      0.15199  23.20s\n",
      "      7       \u001b[36m2.38359\u001b[0m       \u001b[32m2.38184\u001b[0m      1.00073      0.15199  23.15s\n",
      "      8       \u001b[36m2.38062\u001b[0m       \u001b[32m2.38111\u001b[0m      0.99979      0.15270  23.15s\n",
      "      9       \u001b[36m2.37805\u001b[0m       \u001b[32m2.37811\u001b[0m      0.99998      0.15270  23.16s\n",
      "     10       \u001b[36m2.37530\u001b[0m       \u001b[32m2.37505\u001b[0m      1.00010      0.15270  23.15s\n",
      "     11       \u001b[36m2.37361\u001b[0m       2.37596      0.99901      0.15199  23.17s\n",
      "     12       \u001b[36m2.37178\u001b[0m       \u001b[32m2.37130\u001b[0m      1.00020      0.15341  23.15s\n",
      "     13       \u001b[36m2.37019\u001b[0m       2.37216      0.99917      0.15199  23.14s\n",
      "     14       \u001b[36m2.36885\u001b[0m       \u001b[32m2.36852\u001b[0m      1.00014      0.15199  23.16s\n",
      "     15       \u001b[36m2.36721\u001b[0m       2.36894      0.99927      0.15199  23.13s\n",
      "     16       \u001b[36m2.36567\u001b[0m       \u001b[32m2.36584\u001b[0m      0.99993      0.15199  23.20s\n",
      "     17       \u001b[36m2.36438\u001b[0m       2.36670      0.99902      0.15199  23.14s\n",
      "     18       \u001b[36m2.36323\u001b[0m       2.36600      0.99883      0.15199  23.15s\n",
      "     19       \u001b[36m2.36189\u001b[0m       \u001b[32m2.36424\u001b[0m      0.99900      0.15341  23.15s\n",
      "     20       \u001b[36m2.36033\u001b[0m       \u001b[32m2.36122\u001b[0m      0.99962      0.15341  23.50s\n",
      "     21       \u001b[36m2.35910\u001b[0m       2.36123      0.99910      0.15199  23.34s\n",
      "     22       \u001b[36m2.35809\u001b[0m       \u001b[32m2.35928\u001b[0m      0.99950      0.15341  23.22s\n",
      "     23       \u001b[36m2.35718\u001b[0m       \u001b[32m2.35923\u001b[0m      0.99913      0.15341  23.14s\n",
      "     24       \u001b[36m2.35629\u001b[0m       \u001b[32m2.35752\u001b[0m      0.99948      0.15341  23.15s\n",
      "     25       \u001b[36m2.35576\u001b[0m       2.35902      0.99861      0.15341  23.15s\n",
      "     26       \u001b[36m2.35494\u001b[0m       2.35836      0.99855      0.15270  23.31s\n",
      "     27       \u001b[36m2.35431\u001b[0m       \u001b[32m2.35728\u001b[0m      0.99874      0.15270  23.15s\n",
      "     28       \u001b[36m2.35337\u001b[0m       \u001b[32m2.35466\u001b[0m      0.99945      0.15270  23.47s\n",
      "     29       \u001b[36m2.35302\u001b[0m       2.35632      0.99860      0.15341  23.46s\n",
      "     30       \u001b[36m2.35222\u001b[0m       2.35508      0.99878      0.15199  23.18s\n",
      "     31       \u001b[36m2.35145\u001b[0m       \u001b[32m2.35281\u001b[0m      0.99942      0.15199  23.30s\n",
      "     32       \u001b[36m2.35112\u001b[0m       2.35453      0.99855      0.15199  23.78s\n",
      "     33       \u001b[36m2.35021\u001b[0m       2.35353      0.99859      0.15270  23.31s\n",
      "     34       \u001b[36m2.34977\u001b[0m       2.35338      0.99847      0.15199  23.44s\n",
      "     35       \u001b[36m2.34913\u001b[0m       2.35289      0.99840      0.15199  23.61s\n",
      "     36       \u001b[36m2.34856\u001b[0m       \u001b[32m2.35252\u001b[0m      0.99832      0.15199  23.24s\n",
      "     37       \u001b[36m2.34811\u001b[0m       \u001b[32m2.35209\u001b[0m      0.99831      0.15199  23.24s\n",
      "     38       \u001b[36m2.34763\u001b[0m       \u001b[32m2.35171\u001b[0m      0.99827      0.15199  23.49s\n",
      "     39       \u001b[36m2.34744\u001b[0m       \u001b[32m2.35145\u001b[0m      0.99830      0.15270  23.81s\n",
      "     40       \u001b[36m2.34711\u001b[0m       \u001b[32m2.35111\u001b[0m      0.99830      0.15270  23.63s\n",
      "     41       \u001b[36m2.34641\u001b[0m       \u001b[32m2.35018\u001b[0m      0.99840      0.15270  23.21s\n",
      "     42       \u001b[36m2.34623\u001b[0m       \u001b[32m2.34963\u001b[0m      0.99855      0.15199  23.24s\n",
      "     43       \u001b[36m2.34549\u001b[0m       \u001b[32m2.34891\u001b[0m      0.99854      0.15199  23.42s\n",
      "     44       \u001b[36m2.34517\u001b[0m       \u001b[32m2.34874\u001b[0m      0.99848      0.15199  23.59s\n",
      "     45       \u001b[36m2.34468\u001b[0m       \u001b[32m2.34803\u001b[0m      0.99857      0.15270  23.40s\n",
      "     46       \u001b[36m2.34426\u001b[0m       \u001b[32m2.34782\u001b[0m      0.99849      0.15270  23.39s\n",
      "     47       \u001b[36m2.34345\u001b[0m       \u001b[32m2.34705\u001b[0m      0.99846      0.15199  23.40s\n",
      "     48       \u001b[36m2.34314\u001b[0m       \u001b[32m2.34688\u001b[0m      0.99841      0.15270  23.36s\n",
      "     49       \u001b[36m2.34151\u001b[0m       \u001b[32m2.34619\u001b[0m      0.99801      0.15270  23.32s\n",
      "     50       \u001b[36m2.34089\u001b[0m       \u001b[32m2.34606\u001b[0m      0.99780      0.15270  23.31s\n",
      "     51       \u001b[36m2.34051\u001b[0m       \u001b[32m2.34541\u001b[0m      0.99791      0.15341  23.36s\n",
      "     52       \u001b[36m2.34044\u001b[0m       \u001b[32m2.34533\u001b[0m      0.99792      0.15554  23.38s\n",
      "     53       \u001b[36m2.33980\u001b[0m       \u001b[32m2.34471\u001b[0m      0.99790      0.15554  23.40s\n",
      "     54       \u001b[36m2.33935\u001b[0m       \u001b[32m2.34452\u001b[0m      0.99780      0.15554  23.38s\n",
      "     55       \u001b[36m2.33813\u001b[0m       \u001b[32m2.34287\u001b[0m      0.99797      0.15483  23.41s\n",
      "     56       \u001b[36m2.33803\u001b[0m       2.34410      0.99741      0.15483  23.38s\n",
      "     57       \u001b[36m2.33763\u001b[0m       2.34357      0.99747      0.15554  23.39s\n",
      "     58       \u001b[36m2.33740\u001b[0m       2.34353      0.99738      0.15554  23.41s\n",
      "     59       \u001b[36m2.33658\u001b[0m       2.34298      0.99727      0.15625  23.43s\n",
      "     60       \u001b[36m2.33635\u001b[0m       2.34293      0.99719      0.15625  23.41s\n",
      "     61       \u001b[36m2.33558\u001b[0m       \u001b[32m2.34266\u001b[0m      0.99698      0.15625  23.26s\n",
      "     62       \u001b[36m2.33517\u001b[0m       \u001b[32m2.34230\u001b[0m      0.99696      0.15625  23.53s\n",
      "     63       2.33560       2.34271      0.99696      0.15554  23.35s\n",
      "     64       \u001b[36m2.33392\u001b[0m       \u001b[32m2.34197\u001b[0m      0.99656      0.15625  23.42s\n",
      "     65       2.33426       2.34217      0.99662      0.15554  23.32s\n",
      "     66       \u001b[36m2.33370\u001b[0m       2.34200      0.99645      0.15554  23.51s\n",
      "     67       \u001b[36m2.33286\u001b[0m       \u001b[32m2.34187\u001b[0m      0.99616      0.15554  23.39s\n",
      "     68       \u001b[36m2.33230\u001b[0m       \u001b[32m2.34166\u001b[0m      0.99600      0.15554  23.56s\n",
      "     69       \u001b[36m2.33219\u001b[0m       \u001b[32m2.34155\u001b[0m      0.99600      0.15554  23.64s\n",
      "     70       \u001b[36m2.33144\u001b[0m       2.34172      0.99561      0.15483  24.12s\n",
      "     71       \u001b[36m2.33110\u001b[0m       \u001b[32m2.34145\u001b[0m      0.99558      0.15483  24.20s\n",
      "     72       \u001b[36m2.33109\u001b[0m       2.34149      0.99556      0.15554  24.09s\n",
      "     73       \u001b[36m2.33034\u001b[0m       \u001b[32m2.34123\u001b[0m      0.99535      0.15554  23.70s\n",
      "     74       \u001b[36m2.32911\u001b[0m       \u001b[32m2.33983\u001b[0m      0.99542      0.15767  23.20s\n",
      "     75       2.32942       2.34070      0.99518      0.15625  23.65s\n",
      "     76       \u001b[36m2.32824\u001b[0m       \u001b[32m2.33955\u001b[0m      0.99516      0.15625  23.87s\n",
      "     77       \u001b[36m2.32789\u001b[0m       2.33978      0.99492      0.15625  23.60s\n",
      "     78       \u001b[36m2.32672\u001b[0m       \u001b[32m2.33870\u001b[0m      0.99488      0.15696  23.50s\n",
      "     79       \u001b[36m2.32566\u001b[0m       \u001b[32m2.33774\u001b[0m      0.99483      0.15696  23.93s\n",
      "     80       \u001b[36m2.32517\u001b[0m       \u001b[32m2.33758\u001b[0m      0.99469      0.15696  23.28s\n",
      "     81       \u001b[36m2.32412\u001b[0m       \u001b[32m2.33727\u001b[0m      0.99437      0.15625  23.24s\n",
      "     82       \u001b[36m2.32371\u001b[0m       \u001b[32m2.33707\u001b[0m      0.99428      0.15554  23.54s\n",
      "     83       \u001b[36m2.32283\u001b[0m       \u001b[32m2.33684\u001b[0m      0.99400      0.15554  23.24s\n",
      "     84       \u001b[36m2.32217\u001b[0m       \u001b[32m2.33642\u001b[0m      0.99390      0.15483  23.17s\n",
      "     85       \u001b[36m2.32202\u001b[0m       2.33654      0.99379      0.15554  23.35s\n",
      "     86       \u001b[36m2.32117\u001b[0m       \u001b[32m2.33611\u001b[0m      0.99361      0.15412  23.32s\n",
      "     87       \u001b[36m2.32094\u001b[0m       \u001b[32m2.33582\u001b[0m      0.99363      0.15483  23.31s\n",
      "     88       \u001b[36m2.31994\u001b[0m       \u001b[32m2.33568\u001b[0m      0.99326      0.15412  23.31s\n",
      "     89       \u001b[36m2.31935\u001b[0m       \u001b[32m2.33509\u001b[0m      0.99326      0.15341  23.34s\n",
      "     90       2.31942       2.33513      0.99327      0.15270  23.67s\n",
      "     91       \u001b[36m2.31844\u001b[0m       \u001b[32m2.33445\u001b[0m      0.99314      0.15341  23.54s\n",
      "     92       \u001b[36m2.31809\u001b[0m       \u001b[32m2.33407\u001b[0m      0.99315      0.15270  23.25s\n",
      "     93       \u001b[36m2.31740\u001b[0m       \u001b[32m2.33359\u001b[0m      0.99306      0.15341  23.67s\n",
      "     94       \u001b[36m2.31685\u001b[0m       \u001b[32m2.33318\u001b[0m      0.99300      0.15341  23.17s\n",
      "     95       \u001b[36m2.31607\u001b[0m       \u001b[32m2.33232\u001b[0m      0.99303      0.15341  23.15s\n",
      "     96       2.31693       \u001b[32m2.33190\u001b[0m      0.99358      0.15412  23.13s\n",
      "     97       \u001b[36m2.31537\u001b[0m       \u001b[32m2.33074\u001b[0m      0.99341      0.15270  23.13s\n",
      "     98       \u001b[36m2.31457\u001b[0m       \u001b[32m2.32897\u001b[0m      0.99382      0.15128  23.12s\n",
      "     99       \u001b[36m2.31388\u001b[0m       \u001b[32m2.32572\u001b[0m      0.99491      0.15128  23.10s\n",
      "    100       \u001b[36m2.31171\u001b[0m       \u001b[32m2.32189\u001b[0m      0.99562      0.15199  23.11s\n"
     ]
    }
   ],
   "source": [
    "nn=net.fit(X_train,y_train, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers0 = [\n",
    "    # layer dealing with the input data\n",
    "    (layers.InputLayer, {'shape': (None, 3, 200, 200)}),\n",
    "\n",
    "    # first stage of our convolutional layers\n",
    "    (layers.Conv2DLayer, {'num_filters': 96, 'filter_size': (7,7),'stride':(2,2)}),\n",
    "    (layers.BatchNormLayer,{}),\n",
    "#     (layers.normalization),\n",
    "    (layers.MaxPool2DLayer, {'pool_size': (2,2)}),\n",
    "\n",
    "    # second stage of our convolutional layers\n",
    "    (layers.Conv2DLayer, {'num_filters': 128, 'filter_size': 5,'stride':2}),\n",
    "    (layers.BatchNormLayer,{}),\n",
    "#     (layers.normalization),\n",
    "    (layers.MaxPool2DLayer, {'pool_size': (2,2)}),\n",
    "\n",
    "    # third stage of our convolution layers\n",
    "    (layers.Conv2DLayer, {'num_filters': 512, 'filter_size': 3}),\n",
    "#     (layers.MaxPool2DLayer, {'pool_size': 2}),\n",
    "    (layers.Conv2DLayer, {'num_filters': 512, 'filter_size': 3}),\n",
    "\n",
    "    (layers.Conv2DLayer, {'num_filters': 512, 'filter_size': 3}),\n",
    "    (layers.MaxPool2DLayer, {'pool_size': 2}),\n",
    "\n",
    "#     (layers.Conv2DLayer, {'num_filters': 512, 'filter_size': 3}),\n",
    "#     (layers.MaxPool2DLayer, {'pool_size': 2,'stride':2}),\n",
    "\n",
    "\n",
    "\n",
    "    # two dense layers with dropout\n",
    "    (layers.DenseLayer, {'num_units': 2048}),\n",
    "    (layers.DropoutLayer, {}),\n",
    "    (layers.DenseLayer, {'num_units': 1024}),\n",
    "\n",
    "    # the output layer\n",
    "    (layers.DenseLayer, {'num_units': 11, 'nonlinearity': lasagne.nonlinearities.softmax}),\n",
    "]\n",
    "net0 = NeuralNet(\n",
    "    layers=layers0,\n",
    "    update_learning_rate=0.0001,\n",
    "    max_epochs=100,\n",
    "\n",
    "    update=adam,\n",
    "   \n",
    "\n",
    "    objective_l2=0.0025,\n",
    "    batch_iterator_train=BatchIterator(batch_size=60),\n",
    "    batch_iterator_test=BatchIterator(batch_size=29),\n",
    "    train_split=TrainSplit(eval_size=0.02),\n",
    "\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bi = BatchIterator(batch_size=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nolearn.lasagne import PrintLayerInfo\n",
    "\n",
    "layer_info=PrintLayerInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "type(y_train)\n",
    "print max(y_train)\n",
    "y_train=np.asarray(y_train)\n",
    "X_train=np.asarray(X_train)\n",
    "y_train=y_train.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258780,)\n",
      "(258780,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 11937739 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name         size\n",
      "---  -----------  ---------\n",
      "  0  input0       3x200x200\n",
      "  1  conv2d1      96x97x97\n",
      "  2  batchnorm2   96x97x97\n",
      "  3  maxpool2d3   96x48x48\n",
      "  4  conv2d4      128x22x22\n",
      "  5  batchnorm5   128x22x22\n",
      "  6  maxpool2d6   128x11x11\n",
      "  7  conv2d7      512x9x9\n",
      "  8  conv2d8      512x7x7\n",
      "  9  conv2d9      512x5x5\n",
      " 10  maxpool2d10  512x2x2\n",
      " 11  dense11      2048\n",
      " 12  dropout12    2048\n",
      " 13  dense13      1024\n",
      " 14  dense14      11\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  --------\n",
      "      1       \u001b[36m3.51257\u001b[0m       \u001b[32m4.05365\u001b[0m      0.86652      0.39959  5125.20s\n",
      "      2       \u001b[36m0.84329\u001b[0m       \u001b[32m3.12620\u001b[0m      0.26975      0.43407  4777.53s\n",
      "      3       \u001b[36m0.57383\u001b[0m       \u001b[32m2.86030\u001b[0m      0.20062      0.47858  4777.83s\n",
      "      4       \u001b[36m0.45792\u001b[0m       \u001b[32m2.33676\u001b[0m      0.19596      0.53455  4823.67s\n",
      "      5       \u001b[36m0.39173\u001b[0m       2.39558      0.16352      0.55380  4786.07s\n",
      "      6       \u001b[36m0.34837\u001b[0m       \u001b[32m2.03191\u001b[0m      0.17145      0.57973  4796.95s\n",
      "      7       \u001b[36m0.31874\u001b[0m       \u001b[32m1.77120\u001b[0m      0.17996      0.61084  4782.02s\n",
      "      8       \u001b[36m0.29753\u001b[0m       2.04789      0.14528      0.58310  4774.17s\n",
      "      9       \u001b[36m0.28240\u001b[0m       2.38746      0.11829      0.53532  4779.04s\n",
      "     10       \u001b[36m0.26955\u001b[0m       \u001b[32m1.60250\u001b[0m      0.16821      0.66488  5522.40s\n",
      "     11       \u001b[36m0.25717\u001b[0m       \u001b[32m1.38433\u001b[0m      0.18577      0.68848  4813.66s\n",
      "     12       \u001b[36m0.24936\u001b[0m       1.53654      0.16229      0.66690  4782.11s\n",
      "     13       \u001b[36m0.24053\u001b[0m       1.92738      0.12480      0.59022  4776.37s\n",
      "     14       \u001b[36m0.23755\u001b[0m       1.87384      0.12677      0.59438  4777.95s\n",
      "     15       \u001b[36m0.23139\u001b[0m       1.48563      0.15575      0.66036  4870.69s\n",
      "     16       \u001b[36m0.22488\u001b[0m       1.92912      0.11657      0.60834  5006.86s\n",
      "     17       \u001b[36m0.22329\u001b[0m       \u001b[32m1.31776\u001b[0m      0.16945      0.67866  4929.70s\n",
      "     18       \u001b[36m0.21643\u001b[0m       1.55811      0.13890      0.64688  4788.66s\n",
      "     19       \u001b[36m0.21333\u001b[0m       1.33286      0.16005      0.73386  5093.01s\n",
      "     20       \u001b[36m0.20944\u001b[0m       \u001b[32m1.21536\u001b[0m      0.17232      0.70949  4779.66s\n",
      "     21       \u001b[36m0.20722\u001b[0m       1.45308      0.14261      0.65573  4855.49s\n",
      "     22       \u001b[36m0.20577\u001b[0m       1.25131      0.16444      0.70851  4775.63s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x7f3dccc31e50>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x7f3dccc315d0>,\n",
       "     check_input=True, custom_scores=None,\n",
       "     layers=[(<class 'lasagne.layers.input.InputLayer'>, {'shape': (None, 3, 200, 200)}), (<class 'lasagne.layers.conv.Conv2DLayer'>, {'filter_size': (7, 7), 'stride': (2, 2), 'num_filters': 96}), (<class 'lasagne.layers.normalization.BatchNormLayer'>, {}), (<class 'lasagne.layers.pool.MaxPool2DLayer'>, ...layers.dense.DenseLayer'>, {'num_units': 11, 'nonlinearity': <function softmax at 0x7f3dccc36aa0>})],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x7f3dc4473de8>, objective_l2=0.0025,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x7f3dcc701140>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x7f3e2d7238c0>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f3e2ce684d0>],\n",
       "     regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x7f3e04a41690>,\n",
       "     update=<function adam at 0x7f3dcc701c08>, update_learning_rate=0.0001,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net0.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net0.save_params_to(\"importantweights.param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raghib/major_pro\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pkl=open('vgg16.pkl','rb')\n",
    "# d = pickle.load(o)\n",
    "a=pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean value', 'synset words', 'model name', 'param values'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.viewkeys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.90147837e-03  -1.80806511e-03   1.36159221e-03 ...,   1.05189125e-03\n",
      "   -5.83238620e-03   1.55499880e-03]\n",
      " [  5.35322493e-03  -2.31539086e-03  -3.61574744e-03 ...,  -8.41525383e-04\n",
      "   -1.55866274e-03   5.22026513e-03]\n",
      " [ -3.13405343e-03  -8.60718792e-05   2.81324098e-03 ...,   2.33084010e-03\n",
      "    4.52873018e-03  -6.23492757e-03]\n",
      " ..., \n",
      " [ -4.24027257e-03  -4.14406357e-04  -7.89196289e-04 ...,   6.79930439e-03\n",
      "    3.37824528e-03   2.13007792e-03]\n",
      " [  2.78731284e-04   9.56191774e-03  -6.20277831e-04 ...,  -2.16196757e-03\n",
      "    5.90845896e-03   1.76626071e-03]\n",
      " [  4.96918161e-04   1.63843471e-03  -9.92762507e-04 ...,  -4.49770268e-05\n",
      "   -3.50919843e-04   5.03490586e-03]]\n"
     ]
    }
   ],
   "source": [
    "len(a['param values'])\n",
    "print a['param values'][28]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
